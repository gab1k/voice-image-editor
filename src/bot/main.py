import nest_asyncio
import os
import logging
from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    ConversationHandler,
    ContextTypes,
    filters,
)
from PIL import Image
import io
from src.models.image_editor import DiffusionImageEditor
from src.models.asr_model import ASRModelWrapper

logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    level=logging.INFO
)
logger = logging.getLogger(__name__)

editor = DiffusionImageEditor(
    model_type="instruct_pix2pix",
    model_name="timbrooks/instruct-pix2pix",
    device="cuda",
    num_inference_steps=20,
    strength=0.75,
    image_guidance_scale=1.5,
    guidance_scale=7.5,
    max_side=1024,
)
asr = ASRModelWrapper(model_type="tone", device="cuda")

WAITING_IMAGE = 0
WAITING_AUDIO = 1


def process_image_with_audio(image_path: str, audio_path: str) -> str:
    # –∑–∞–≥–ª—É—à–∫–∞ - –ø—Ä–æ—Å—Ç–æ –∫–æ–ø–∏—Ä—É–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É, —á—É—Ç—å –ø–æ–∑–∂–µ –æ–±–µ—Ä–Ω–µ–º –≤ –∞—É—Ç–ø—É—Ç –º–æ–¥–µ–ª–∏ 
    output_path = image_path.replace("_input", "_output")
    if output_path == image_path:
        output_path = image_path.rsplit(".", 1)[0] + "_edited." + image_path.rsplit(".", 1)[1]
    
    with Image.open(image_path) as img:
        print("–°—Ç–∞—Ä—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑ –ø—É—Ç–∏: ", audio_path)
        audio_text = asr.transcribe(audio_path)
        print(audio_text)
        print("–°—Ç–∞—Ä—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        result_img = editor.edit(image=img, instruction=audio_text)
        print("–ö–æ–Ω–µ—Ü —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        result_img.save(output_path)
    
    return output_path


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –≥–æ–ª–æ—Å–æ–≤—ã–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º.\n\n –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –∫–∞—Ä—Ç–∏–Ω–∫—É, –∫–æ—Ç–æ—Ä—É—é —Ö–æ—á–µ—à—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å."
    )
    return WAITING_IMAGE


async def receive_image(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    user = update.effective_user
    
    photo = update.message.photo[-1]
    file = await photo.get_file()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    os.makedirs("temp", exist_ok=True)
    image_path = f"temp/{user.id}_input.jpg"
    await file.download_to_drive(image_path)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—É—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
    context.user_data["image_path"] = image_path
    
    await update.message.reply_text(
        "–ö–∞—Ä—Ç–∏–Ω–∫–∞ –ø–æ–ª—É—á–µ–Ω–∞!\n\n –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏, —á—Ç–æ –Ω—É–∂–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ."
    )
    return WAITING_AUDIO


async def receive_audio(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    user = update.effective_user
    
    if update.message.voice:
        audio = update.message.voice
        audio_ext = "ogg"
    elif update.message.audio:
        audio = update.message.audio
        audio_ext = "mp3"
    else:
        await update.message.reply_text(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª."
        )
        return WAITING_AUDIO
    
    file = await audio.get_file()
    audio_path = f"temp/{user.id}_audio.{audio_ext}"
    await file.download_to_drive(audio_path)

    image_path = context.user_data.get("image_path")
    
    if not image_path or not os.path.exists(image_path):
        await update.message.reply_text(
            " –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—á–Ω–∏ —Å–Ω–∞—á–∞–ª–∞ —Å /start"
        )
        return ConversationHandler.END
    
    await update.message.reply_text("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
    
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        output_path = process_image_with_audio(image_path, audio_path)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        with open(output_path, "rb") as photo_file:
            await update.message.reply_photo(
                photo=photo_file,
                caption=" –ì–æ—Ç–æ–≤–æ! –í–æ—Ç –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."
            )
        
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for path in [image_path, audio_path, output_path]:
            if os.path.exists(path):
                os.remove(path)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        await update.message.reply_text(
            f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}"
        )
    
    # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    context.user_data.clear()
    
    await update.message.reply_text(
        "üîÑ –•–æ—á–µ—à—å –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –µ—â—ë –æ–¥–Ω—É –∫–∞—Ä—Ç–∏–Ω–∫—É? –û—Ç–ø—Ä–∞–≤—å /start"
    )
    return ConversationHandler.END


async def cancel(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    image_path = context.user_data.get("image_path")
    if image_path and os.path.exists(image_path):
        os.remove(image_path)
    
    context.user_data.clear()
    
    await update.message.reply_text(
        "–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞. –û—Ç–ø—Ä–∞–≤—å /start —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –∑–∞–Ω–æ–≤–æ."
    )
    return ConversationHandler.END


async def unexpected_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π."""
    await update.message.reply_text(
        "–ù–µ –ø–æ–Ω–∏–º–∞—é. –û—Ç–ø—Ä–∞–≤—å /start —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏."
    )


def main() -> None:

    TELEGRAM_BOT_TOKEN ='***'
    
    token = TELEGRAM_BOT_TOKEN
    application = Application.builder().token(token).build()
    
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("start", start)],
        states={
            WAITING_IMAGE: [
                MessageHandler(filters.PHOTO, receive_image),
            ],
            WAITING_AUDIO: [
                MessageHandler(filters.VOICE | filters.AUDIO, receive_audio),
            ],
        },
        fallbacks=[CommandHandler("cancel", cancel)],
    )
    
    application.add_handler(conv_handler)
    application.add_handler(MessageHandler(filters.ALL, unexpected_message))
    
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    application.run_polling(allowed_updates=Update.ALL_TYPES)


if __name__ == "__main__":
    main()
